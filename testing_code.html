
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Testing code &#8212; Quality Assurance of Code for Analysis and Research</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css?v=a5c4661c" />
    <link rel="stylesheet" type="text/css" href="_static/admonitions.css?v=1956eba1" />
    <link rel="stylesheet" type="text/css" href="_static/accessibility.css?v=6e02104c" />
    <link rel="stylesheet" type="text/css" href="_static/markdown_within_tabs.css?v=d7e1104e" />
    <link rel="stylesheet" type="text/css" href="_static/logo.css?v=1c56504a" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script src="_static/tabs.js?v=3030b3cb"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'testing_code';</script>
    <link rel="icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Automating code quality assurance" href="continuous_integration.html" />
    <link rel="prev" title="Peer review" href="peer_review.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/duck_book_logo.svg" class="logo__image only-light" alt="Quality Assurance of Code for Analysis and Research - Home"/>
    <script>document.write(`<img src="_static/duck_book_logo.svg" class="logo__image only-dark" alt="Quality Assurance of Code for Analysis and Research - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary of terms</a></li>
<li class="toctree-l1"><a class="reference internal" href="managers_guide.html">Managing analytical code development</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="checklists.html">Code quality assurance checklists</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="checklist_lower.html">Lower quality assurance</a></li>
<li class="toctree-l2"><a class="reference internal" href="checklist_moderate.html">Moderate quality assurance</a></li>
<li class="toctree-l2"><a class="reference internal" href="checklist_higher.html">Higher quality assurance</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Guidance</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="principles.html">Principles</a></li>
<li class="toctree-l1"><a class="reference internal" href="modular_code.html">Modular code</a></li>
<li class="toctree-l1"><a class="reference internal" href="readable_code.html">Readable code</a></li>
<li class="toctree-l1"><a class="reference internal" href="project_structure.html">Structuring your project</a></li>
<li class="toctree-l1"><a class="reference internal" href="code_documentation.html">Code documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="project_documentation.html">Project documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="version_control.html">Version control</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">Data management</a></li>
<li class="toctree-l1"><a class="reference internal" href="peer_review.html">Peer review</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Testing code</a></li>
<li class="toctree-l1"><a class="reference internal" href="continuous_integration.html">Automating code quality assurance</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="learning.html">Learning resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Tools</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/best-practice-and-impact/qa-of-code-guidance" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/best-practice-and-impact/qa-of-code-guidance/edit/main/book/testing_code.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/best-practice-and-impact/qa-of-code-guidance/issues/new?title=Issue%20on%20page%20%2Ftesting_code.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/testing_code.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Testing code</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-should-i-test">What should I test?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-are-tests-structured">How are tests structured?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#write-reproducible-tests">Write reproducible tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#write-repeatable-tests">Write repeatable tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-all-tests-against-each-change-to-your-code">Run all tests against each change to your code</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#record-the-outcomes-of-your-tests">Record the outcomes of your tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minimise-your-test-data">Minimise your test data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#structure-test-files-to-match-code-structure">Structure test files to match code structure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#structuring-tests">Structuring tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-that-new-logic-is-correct-using-unit-tests">Test that new logic is correct using unit tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-that-different-parts-of-the-code-interact-correctly-using-integration-tests">Test that different parts of the code interact correctly using integration tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-that-the-analysis-runs-as-expected-using-end-to-end-tests">Test that the analysis runs as expected using end-to-end tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#good-practices-for-integration-and-end-to-end-testing">Good practices for integration and end-to-end testing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#isolate-code-tests-from-external-systems">Isolate code tests from external systems</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#write-tests-to-assure-that-bugs-are-fixed">Write tests to assure that bugs are fixed</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#write-tests-before-writing-logic">Write tests before writing logic</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelling-relevant-testing">Modelling-relevant testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#acceptance-testing">Acceptance testing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-and-using-appropriate-metrics">Defining and Using Appropriate Metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation-techniques">Cross-Validation Techniques</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stress-testing">Stress Testing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sensitivity-analysis">Sensitivity Analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-interpretability">Model Interpretability</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-optimisation">Model Optimisation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reduce-repetition-in-test-code-fixtures-and-parameterised-tests">Reduce repetition in test code (fixtures and parameterised tests)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-fixtures-to-reduce-repetition-in-test-set-up">Use fixtures to reduce repetition in test set up</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-parameterisation-to-reduce-repetition-in-test-logic">Use parameterisation to reduce repetition in test logic</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-source-code">Define Source Code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-parameterisation">Simple Parameterisation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stacked-parameterisation">Stacked Parameterisation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-sql">Testing SQL</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#in-a-time-crunch-the-risks-to-skipping-tests">In a time crunch? The risks to skipping tests</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="testing-code">
<h1>Testing code<a class="headerlink" href="#testing-code" title="Link to this heading">#</a></h1>
<p>Code documentation helps others to understand what you expect your code to do and how to use it. Code tests verify that your analytical code is working as expected.</p>
<p>You cannot confirm your code works correctly if you don’t carry out tests, so you cannot be confident that your analysis is fit for purpose without them.<br />
Good tests tell a story - given this data, having run this code, we expect this output.</p>
<p>Testing brings strong benefits. It helps you assure your code quality and makes developing your code more efficient.
Code that has not been tested is more likely to contain errors and need more maintenance in the future.</p>
<section id="what-should-i-test">
<h2>What should I test?<a class="headerlink" href="#what-should-i-test" title="Link to this heading">#</a></h2>
<p>The question you need to answer here is a simple one:</p>
<p>How can I demonstrate that my code does what it is supposed to do?</p>
<p>As the developer of the code, you are best placed to decide what tests you need to put in place to answer that question confidently.</p>
<p>Take a risk-based approach to testing. You should use tests proportionately based on your analysis.  This usually means writing more tests for parts of your code that are very new, more complex, or carry more risk.</p>
<p>When you are developing your tests, here are some points to think about:</p>
<ol class="arabic simple">
<li><p>You don’t need to test everything. It is realistic to assume that third party functions and tools which are adequately quality assured (and you can verify this) work as intended.  For example, if you use R you would not expect to write tests to verify that simple arithmetic, base R, or packages published on <a class="reference external" href="https://cran.r-project.org/">CRAN</a> operate correctly, because there is already sufficient assurance. You may be less confident about very new functionality from third parties, or experimental tools. Here, you might decide you do need to do some extra validation.</p></li>
<li><p>Think carefully about whether third party tools really do what you need for your particular context.  For example, the base R <code class="docutils literal notranslate"><span class="pre">round()</span></code> function intentionally behaves differently to the rounding function in Excel. While we can be confident that <code class="docutils literal notranslate"><span class="pre">round()</span></code> works as specified, does it produce what you need?</p></li>
<li><p>Testing is a great way to verify that your approach is the right one. By thinking about what to test, you challenge your own assumptions and the way you have done things. This can reveal issues or scenarios that you had not considered. It means the code you write should be more resilient.</p></li>
<li><p>Be guided by the risks you need to mitigate. For example, if inputs are invalid or unusual, do you want the code to stop with an error message or do something else? Use tests to check that the code does the right thing at the right time.</p></li>
</ol>
</section>
<section id="how-are-tests-structured">
<h2>How are tests structured?<a class="headerlink" href="#how-are-tests-structured" title="Link to this heading">#</a></h2>
<p>Tests come in many shapes and sizes, but usually follow the pattern:</p>
<ol class="arabic simple">
<li><p>Arrange - set up any objects needed for your test, for example sample input data and expected output data.</p></li>
<li><p>Act - run the code that you are testing (one or more functions or methods).</p></li>
<li><p>Assert - verify that the code performed the expected action, for example, that the output matched the expected output.</p></li>
</ol>
<div class="admonition-learning admonition">
<p class="admonition-title">Key Learning</p>
<p>Follow the <a class="reference external" href="https://learninghub.ons.gov.uk/course/view.php?id=1171">Introduction to Unit Testing course</a> for applied examples in Python and R.
This course also covers writing and documenting functions, and error handling.</p>
<p>Other useful learning resources include:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.pytest.org/en/stable/getting-started.html"><code class="docutils literal notranslate"><span class="pre">pytest</span></code> getting started</a></p></li>
<li><p>Real Python <a class="reference external" href="https://realpython.com/python-testing/">Getting Started With Testing in Python</a></p></li>
<li><p>Hadley Wickham’s <a class="reference external" href="https://vita.had.co.nz/papers/testthat.pdf">testthat: getting started with testing</a> and <a class="reference external" href="https://r-pkgs.org/testing-design.html">testing design in R</a></p></li>
</ul>
</div>
<p>In this section, we assume that you are using a testing framework to run your tests (for example, <code class="docutils literal notranslate"><span class="pre">pytest</span></code> for Python or <code class="docutils literal notranslate"><span class="pre">testthat</span></code> for R) and have your code in a package.
It is more difficult to test code that is not in a package and therefore follow the testing good practices described here.</p>
</section>
<section id="write-reproducible-tests">
<h2>Write reproducible tests<a class="headerlink" href="#write-reproducible-tests" title="Link to this heading">#</a></h2>
<p>As an analyst, you routinely check that your analysis is carried out correctly.
You might do this informally by running all or part of your analysis with example data or subsets of real data.</p>
<p>These tests give you confidence that your analysis is correct.
However, it’s important you are able to produce the same checks against your code reproducibly.
Code changes over time, so you need to be able to repeat these checks against the updated code.
Additionally, other analysts should be able to carry out the same checks and get the same results.</p>
<p>You can consistently repeat the same steps when you represent your tests as code.
This lets you or another analyst carry out the same verification again to get the same results.
When you have carried out a test manually, you should ensure that you add a code test to reproduce this.</p>
<p>Code that you write for testing should also follow the good practices described earlier on in this book, in particular <a class="reference internal" href="readable_code.html"><span class="doc std std-doc">Readable code</span></a>.</p>
</section>
<section id="write-repeatable-tests">
<h2>Write repeatable tests<a class="headerlink" href="#write-repeatable-tests" title="Link to this heading">#</a></h2>
<p>You need your tests to be repeatable for you to be able to trust their results.
This means they should give the same outcome if you run them more than once against the same version of your analysis code.</p>
<p>For tests to run repeatably, each test must be independent.
There should not be a shared state between tests, for example a test should not depend on another test having already run.
You could intentionally randomise the order that tests are executed to encourage this.</p>
<p>Where possible, tests should be deterministic.
As such, the only reason for a test to fail should be that the code being tested is incorrect.
Where your code relies on randomness tests should reuse the same random seed each time they are run.</p>
<p>Where this is not possible/logical for the scenario that you are testing, you may want to run the test
case multiple times and make an assertion about the distribution of the outcomes instead.
For example, if you are testing a function that simulates a coin flip you might run it 100 times and
check the proportion of heads versus tails is close to half (within a reasonable range).</p>
</section>
<section id="run-all-tests-against-each-change-to-your-code">
<h2>Run all tests against each change to your code<a class="headerlink" href="#run-all-tests-against-each-change-to-your-code" title="Link to this heading">#</a></h2>
<p>Run <strong>all</strong> tests whenever you make changes to your analysis.
This ensures that changes do not break the existing, intended functionality of your code.
Running the entire collection of tests has the added benefit of detecting unexpected side-effects of your changes.
For example, you might detect an unexpected failure in part of your code that you didn’t change.</p>
<p>If you run tests regularly, you will be more able to fix any issues before changes are added to a stable or production version of your code (e.g. the <code class="docutils literal notranslate"><span class="pre">main</span></code> Git branch).</p>
<p>If you have altered the functionality of your code, this will likely break existing tests.
Failing tests here act as a good reminder that you should update your tests and documentation to reflect the new functionality.
Many testing frameworks support writing tests as examples in the function documentation, which ties these together nicely.</p>
<p>It’s not easy to remember to run your tests manually at regular intervals.
And you’re right to think “surely this could be automated too?”.
Use <a class="reference internal" href="continuous_integration.html#continuous-integration"><span class="std std-ref">continuous integration</span></a> to automate
the running of tests. This way, you can trigger tests to run when any changes are made to your
remote version control repository.</p>
</section>
<section id="record-the-outcomes-of-your-tests">
<h2>Record the outcomes of your tests<a class="headerlink" href="#record-the-outcomes-of-your-tests" title="Link to this heading">#</a></h2>
<p>For auditability, it is important you record the outcome from running tests.
Record the test outcomes with the code, so that
it is clear which tests have been run successfully for a given version of the code.</p>
<p>As mentioned above, automating the running of tests on a version control platform is the simplest and
most effective way to achieve this association between the code version and test outcomes.
See <a class="reference internal" href="continuous_integration.html"><span class="doc std std-doc">Automating code quality assurance</span></a> for further guidance on using these tools.</p>
</section>
<section id="minimise-your-test-data">
<h2>Minimise your test data<a class="headerlink" href="#minimise-your-test-data" title="Link to this heading">#</a></h2>
<p>Tests for analytical code will usually require data. To ensure that tests are clear in their meaning, you should use the smallest possible dataset for a test.</p>
<p>Good test data are:</p>
<ul class="simple">
<li><p>only just detailed enough data to carry out the test</p></li>
<li><p>fake, static (hardcoded), and readable</p></li>
<li><p>stored closely to the test</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>You must not copy the output from running your code to create your expected test outcomes.
If you do this the test will check that the function is running in the same way that it ran when you generated the data.
This assumes that your function is working correctly.</p>
<p>You must create your test data independently, ensuring that it reflects how you want your code to work, rather than how it currently works.</p>
</div>
<p>It’s tempting to create a test dataset that closely mimics your real data, like the example below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">my_package</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_columns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pandas.testing</span><span class="w"> </span><span class="kn">import</span> <span class="n">assert_frame_equal</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_sum_columns</span><span class="p">():</span>
    <span class="n">expected_output</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="s1">&#39;region_1_sales&#39;</span><span class="p">:</span>            <span class="p">[</span><span class="mi">1000</span><span class="p">,</span>  <span class="mi">50000</span><span class="p">,</span> <span class="mi">500</span> <span class="p">,</span> <span class="mi">30000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span>   <span class="mi">50000</span> <span class="p">],</span>
        <span class="s1">&#39;region_2_sales&#39;</span><span class="p">:</span>            <span class="p">[</span><span class="mi">4000</span><span class="p">,</span>  <span class="mi">45000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">13000</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span>   <span class="mi">80000</span> <span class="p">],</span>
        <span class="o">...</span>
        <span class="s1">&#39;region_30_sales&#39;</span><span class="p">:</span>           <span class="p">[</span><span class="mi">1500</span><span class="p">,</span>  <span class="mi">32000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">41000</span><span class="p">,</span> <span class="mi">40000</span><span class="p">,</span>   <span class="mi">10000</span> <span class="p">],</span>
        <span class="s1">&#39;total_sales&#39;</span><span class="p">:</span>               <span class="p">[</span><span class="mi">85000</span><span class="p">,</span> <span class="mi">92000</span><span class="p">,</span> <span class="mi">7000</span><span class="p">,</span> <span class="mi">110000</span><span class="p">,</span> <span class="mi">600000</span><span class="p">,</span> <span class="mi">400000</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">expected_output</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;total_sales&#39;</span><span class="p">)</span>

    <span class="n">actual_output</span> <span class="o">=</span> <span class="n">sum_columns</span><span class="p">(</span>
        <span class="n">df</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span>
        <span class="n">column_to_assign</span><span class="o">=</span><span class="s2">&quot;total_sales&quot;</span><span class="p">,</span>
        <span class="n">columns_to_sum</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;region_1_sales&quot;</span><span class="p">,</span> <span class="s2">&quot;region_2_sales&quot;</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="n">assert_frame_equal</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">actual_output</span><span class="p">)</span>
</pre></div>
</div>
<p>However, you can still conduct the same test with much less data like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_sum_columns</span><span class="p">():</span>
    <span class="n">expected_output</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="s1">&#39;input_1&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="s1">&#39;input_2&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="s1">&#39;outcome&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">expected_output</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;outcome&#39;</span><span class="p">)</span>

    <span class="n">actual_output</span> <span class="o">=</span> <span class="n">sum_columns</span><span class="p">(</span>
        <span class="n">df</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span>
        <span class="n">column_to_assign</span><span class="o">=</span><span class="s2">&quot;outcome&quot;</span><span class="p">,</span>
        <span class="n">columns_to_sum</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input_1&quot;</span><span class="p">,</span> <span class="s2">&quot;input_2&quot;</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="n">assert_frame_equal</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">actual_output</span><span class="p">)</span>
</pre></div>
</div>
<p>Using minimal and general data in the test has made it clearer what is being tested, and also avoids any unnecessary disclosure.
In this case, the function is very generic, so the test doesn’t need to know the names of real columns in our data or even have similar values in the data.
The test data are focussed on testing specific, realistic cases.
This makes it easy to see that this function works correctly with positive, negative and zero values.</p>
<p>Note that the way you write your test affects how the function is implemented.
Using minimal, generalised data encourages you to follow good practices when designing your function.
This function doesn’t know the name of the columns that it will use in advance, so they are passed as parameters.
This makes the function reusable.
You might have named the original function <code class="docutils literal notranslate"><span class="pre">sum_sales_columns</span></code>, but the more general name used here makes it clear
that you could use this to sum columns in any other context.</p>
<p>The example above is a single test function, but could have created separate tests for each scenario and included tests for more than two input columns, for example.</p>
</section>
<section id="structure-test-files-to-match-code-structure">
<h2>Structure test files to match code structure<a class="headerlink" href="#structure-test-files-to-match-code-structure" title="Link to this heading">#</a></h2>
<p>In <a class="reference internal" href="modular_code.html"><span class="doc std std-doc">Modular code</span></a> we describe how complexity can be managed by separating code into related groups.
Modular, well-structured code is easier to write tests for.
But we also want to make it easy to identify which tests relate to which parts of our code.</p>
<p>You should mirror the structure of your code in the structure of your test files.
You might use one test file per function/class or one test file per module.
Overall, the aim is to make it easy to find the tests for a given function or class and vice versa.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Python</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">R</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span>project/
│
├── src/
│   ├── __init__.py
│   ├── math.py
│   ├── strings.py
│   └── api.py
│
└── tests/
    ├── unit/
    │   ├── test_math.py
    │   └── test_strings.py
    │
    ├── integration/
    │   └── test_api.py
    │
    └── end_to_end/
        └── test_end_to_end_pipeline.py
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span>project/  
│  
├── .Rproj  
│  
├── R/  
│   ├── math.R  
│   ├── strings.R  
│   └── api.R  
│  
└── tests/  
    │  
    ├── testthat/  
    │   ├── test-maths_abs.R  
    │   ├── test-maths_sum.R  
    │   └── test-strings_option.R  
    │  
    └── testthat.R  
</pre></div>
</div>
</div></div>
<p>The Python example above has one file containing unit tests for each module (group of related functions and classes).
When using this structure, you may want to also group multiple test functions into test classes.
Having one test class per function/class that you are testing will make it clear that the group of tests relates to that function or class in your source code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># An example for tests/unit/test_math.py</span>

<span class="k">class</span><span class="w"> </span><span class="nc">TestAbs</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">test_abs_all_positive_values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="o">...</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">test_abs_all_negative_values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="o">...</span>
    
    <span class="o">...</span>


<span class="k">class</span><span class="w"> </span><span class="nc">TestSum</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">test_sum_all_positive_values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="o">...</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">test_sum_all_negative_values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="o">...</span>
    
    <span class="o">...</span>
</pre></div>
</div>
<p>Using classes for unit tests has many additional benefits, allowing reuse of the same logic either by class inheritance, or through fixtures.
Similar to fixtures,
you can use the same pieces of logic through class inheritance in Python.
Note that it is easier to mix up and link unit tests when using class inheritance.
The following code block demonstrates an example of class inheritance which will inherit both the
variable and the <code class="docutils literal notranslate"><span class="pre">test_var_positive</span></code> unit test, meaning three unit tests are run.
You can overwrite the variable within the subclass at any time, but will still inherit defined functions/tests from the parent class.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">TestBase</span><span class="p">:</span>
    <span class="n">var</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">test_var_positive</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">var</span> <span class="o">&gt;=</span> <span class="mi">0</span>

<span class="k">class</span><span class="w"> </span><span class="nc">TestSub</span><span class="p">(</span><span class="n">TestBase</span><span class="p">):</span>
    <span class="n">var</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">test_var_even</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">var</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span>
</pre></div>
</div>
<p>The R  project structure above has one test file per function in the modules.
There are multiple test files for the <code class="docutils literal notranslate"><span class="pre">math.R</span></code> module because it contains more than one function.
Tests in these test files do not need grouping into classes, as the file name is used to indicate exactly which function or class is being tested.
Tests in R are now linked together based on the file, previously named <a class="reference external" href="https://testthat.r-lib.org/reference/context.html">contexts</a>.
Context is now tied to test file name to ensure they are always synced.
The <code class="docutils literal notranslate"><span class="pre">context()</span></code> function is now depreciated and should be removed from your R script.</p>
<p>These are the common conventions for each of Python and R, but are interchangeable.
Use the approach that makes it easiest for developers to identify the relationship between tests and the code they are testing.</p>
<p>Note that some test frameworks allow you to keep the tests in the same file as the code that is being tested.
This is a good way of keeping tests and code associated,
but you should follow good modular code practices to separate unrelated code into different files.
Additional arguments are made to separate tests and functions when you are packaging your code.
If you store unit tests and code in the same file,
the unit tests would also be packaged and installed by additional users.
Therefore when packaging code,
you should move the unit tests to an adjacent test folder as users will not need to have unit tests installed when installing the package.</p>
<p>When separating unit tests into main package and testing scripts, it is important to import your package to ensure the correct functions are being unit tested.
For the module structure outlined previously, use <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">src.math</span> <span class="pre">import</span> <span class="pre">my_math_function</span></code>.
For R, you need to specify the name of your package within the <code class="docutils literal notranslate"><span class="pre">testthat.R</span></code> file within your tests folder.</p>
</section>
<section id="structuring-tests">
<h2>Structuring tests<a class="headerlink" href="#structuring-tests" title="Link to this heading">#</a></h2>
<p>To maintain a consistency across modules you develop, you should follow <a class="reference external" href="https://peps.python.org/pep-0008">PEP8</a> (Python)
or <a class="reference external" href="https://google.github.io/styleguide/Rguide.html">Google</a> / <a class="reference external" href="https://style.tidyverse.org/">tidyverse</a> (R) standards when structuring unit tests.</p>
<p>For python this involves importing all needed functions at the beginning of the test file.
To ensure you import the correct functions from your module,
we recommended you install a local editable version into your virtual environment.
Run <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">-e</span> <span class="pre">.</span></code> and any changes made to your
module functions will also be updated in your python environment.
Following this it is recommended to define fixtures, classes and then test functions.
An example of this is below.
More information can be found in Real Python <a class="reference external" href="https://realpython.com/python-testing/">Getting Started With Testing in Python</a>.</p>
<p>You should follow a similar structure in R, with all modules loaded in the beginning of a test script.
Test contexts and then functions should be defined in turn as shown above.
For more information see <a class="reference external" href="https://r-pkgs.org/testing-design.html">testing design in R</a>.</p>
<p>Generally, tests within the same file should follow some structure or order.
We recommend that the order that functions are defined in the main script is also mirrored
within the test scripts.
This will be easier for future developers to debug and follow and
ensures that no functions have been missed and do not have unit tests written.</p>
</section>
<section id="test-that-new-logic-is-correct-using-unit-tests">
<h2>Test that new logic is correct using unit tests<a class="headerlink" href="#test-that-new-logic-is-correct-using-unit-tests" title="Link to this heading">#</a></h2>
<p>When you implement new logic in code, tests are required to assure that the code works as expected.</p>
<p>To make sure that your code works as expected, you should write tests for each individual unit in your code.
A unit is the smallest modular piece of logic in the code - a function or method.</p>
<p>Unit tests should cover realistic use cases for your function, such as:</p>
<ul class="simple">
<li><p>boundary cases, like the highest and lowest expected input values</p></li>
<li><p>positive, negative, zero, and missing value inputs</p></li>
<li><p>examples that trigger errors that have been defined in your code</p></li>
</ul>
<p>When your function documentation describes the expected inputs to your function, there is less need to test unexpected cases.
If misuse is still likely or risky, then providing the user with an error is the best approach to mitigate this risk.</p>
<p>Reusing logic from an existing package that is already tested does not require tests when we use that logic alone.
You should be aware of whether your dependencies are sufficiently tested.
Newly developed packages or those with very few users are more likely to not be thoroughly tested.</p>
</section>
<section id="test-that-different-parts-of-the-code-interact-correctly-using-integration-tests">
<h2>Test that different parts of the code interact correctly using integration tests<a class="headerlink" href="#test-that-different-parts-of-the-code-interact-correctly-using-integration-tests" title="Link to this heading">#</a></h2>
<p>Integration tests are those that test on a higher level than a unit. This includes testing that:</p>
<ul class="simple">
<li><p>multiple units work together correctly</p></li>
<li><p>multiple high level functions work together (e.g., many units grouped into stages of a pipeline)</p></li>
<li><p>the analysis works with typical inputs from other systems</p></li>
</ul>
<p>Integration tests give you assurance that your analysis is fit for purpose.
Additionally, they give you safety when refactoring or rearranging large parts of code.
Refactoring is an important part of managing the complexity of your analysis as it grows.</p>
<p>You can similarly consider a high level stage of an analysis pipeline.
If you have a stage responsible for imputing missing values, you can create integration tests to check that all values are
imputed and that you used particular imputation methods for specific cases in your test data.
When changes are made to individual imputation methods you might not expect these general characteristics to change.
This test helps to identify cases where this inadvertently has changed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Integration tests are more robust when they focus on general high level outcomes that you don’t expect to change often.
Integration tests that check very specific outcomes will need to be updated with any small change to the logic within the part that is being tested.</p>
</div>
</section>
<section id="test-that-the-analysis-runs-as-expected-using-end-to-end-tests">
<h2>Test that the analysis runs as expected using end-to-end tests<a class="headerlink" href="#test-that-the-analysis-runs-as-expected-using-end-to-end-tests" title="Link to this heading">#</a></h2>
<p>End-to-end testing (sometimes called system testing) checks the entire workflow from start to finish, ensuring all components work correctly in real-world scenarios. While integration testing focuses on the interaction of specific modules, end-to-end testing involves all elements of a pipeline. This is useful when refactoring code for example, by providing assurance that overall functionality remains unchanged.</p>
<p>For example, a piece of analysis has an end-to-end test to check that outputs are generated and the data are the right shape or format. There might also be a “regression” test that checks that the exact values in the output remain the same. After you make any changes to tidy up or refactor the code, these end-to-end tests can be run to assure no functionality has accidentally changed.</p>
<p>Use end-to-end tests to also quality assure a project from an end user’s perspective; these should be run in an environment that replicates the production environment as closely as possible. This type of testing can catch errors that individual unit tests might miss and confirms that the output is fit for purpose and the user requirements are met. End-to-end testing is a form of ‘black box’ testing, meaning the tester verifies functionality without focusing on the underlying code. It is therefore important to use end to end testing alongside other forms of testing such as unit tests.</p>
</section>
<section id="good-practices-for-integration-and-end-to-end-testing">
<h2>Good practices for integration and end-to-end testing<a class="headerlink" href="#good-practices-for-integration-and-end-to-end-testing" title="Link to this heading">#</a></h2>
<p>When devising an integration or end-to-end testing it’s important to follow these good practices:</p>
<ul class="simple">
<li><p>Planning ahead: Have a clear plan of what you want to test and how before you start.</p></li>
<li><p>Testing Early:  Start testing integration as soon as parts are combined rather than waiting until everything is finished. This helps catch issues sooner.</p></li>
<li><p>Use Real Data: Whenever possible, use real data in your tests to make sure everything behaves like it would in the real world. When not possible, make sure the test data reflect the complexities of real data.</p></li>
<li><p>Automate tests: Automate your integration tests. This makes it easier to run them frequently and catch problems quickly.</p></li>
<li><p>Checking dependencies: Make sure to test how different components rely on each other, as issues can arise there.</p></li>
<li><p>Test for failures: don’t just test for success; also check how the system behaves when things go wrong. This helps ensure it handles errors gracefully.</p></li>
<li><p>Keep tests isolated: Try to isolate tests so that one failure doesn’t affect another, making it easier to pinpoint issues.</p></li>
<li><p>Document: Keep a record of tests, results, and issues found. This helps with future testing and understanding what changes might affect integration.</p></li>
</ul>
</section>
<section id="isolate-code-tests-from-external-systems">
<h2>Isolate code tests from external systems<a class="headerlink" href="#isolate-code-tests-from-external-systems" title="Link to this heading">#</a></h2>
<p>Testing code that interacts with an external system can be particularly challenging when you can’t guarantee
that the system will provide you with the same response each time; this could include code querying a database or
making API requests, for example.</p>
<p>Best practice is to separate external system dependencies from your code tests as much as possible. This can mitigate against various risks, depending on your application:</p>
<ul class="simple">
<li><p>Testing database interaction with a production database could result in damage to, or loss of, data.</p></li>
<li><p>Making real API calls when testing a function that handles requests could incur unintended monetary costs.</p></li>
</ul>
<p>Isolating code from external systems allows for tests to run without reliance on the real systems; for example, tests for a database interaction that can still run even if the database connection goes down.
Writing tests in this way means that tests evaluate how your code handles an output or response, and not the system dependency itself.
This is another benefit of enforcing isolation in unit tests - helping you understand when errors are coming from an external system, and when they’re coming from your code.
The unit of code being tested is referred to as the ‘System Under Test’ (SUT).</p>
<p>One way of achieving this is with mocking. This is where a response from an outside system is replaced with a mock object that you can test your code against.
In this example, there’s a function making an API request in <code class="docutils literal notranslate"><span class="pre">src/handle_api_request.py</span></code>, and two test functions in <code class="docutils literal notranslate"><span class="pre">tests/test_handle_api_request.py</span></code>.
The response from <code class="docutils literal notranslate"><span class="pre">requests.get()</span></code> is mocked with a <code class="docutils literal notranslate"><span class="pre">Mock()</span></code> object, to which <code class="docutils literal notranslate"><span class="pre">text</span></code> and <code class="docutils literal notranslate"><span class="pre">status_code</span></code> attributes are assigned.
You can now evaluate the <code class="docutils literal notranslate"><span class="pre">get_response()</span></code> function for how it handles successful and unsuccessful requests; but thanks to the mocking, get requests are not made to <code class="docutils literal notranslate"><span class="pre">http://example.com</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># AI has been used to produce content within this artefact.</span>

<span class="c1"># src/handle_api_request.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_response</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
        <span class="k">raise</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">HTTPError</span><span class="p">(</span><span class="s2">&quot;Unsuccessful request&quot;</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span>

<span class="o">...</span>

<span class="c1"># tests/test_handle_api_request.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">src.api_requests</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_response</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">unittest</span><span class="w"> </span><span class="kn">import</span> <span class="n">mock</span>

<span class="nd">@mock</span><span class="o">.</span><span class="n">patch</span><span class="p">(</span><span class="s2">&quot;requests.get&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_get_response_success</span><span class="p">(</span><span class="n">mock_requests_get</span><span class="p">):</span>
    <span class="n">mock_response</span> <span class="o">=</span> <span class="n">mock</span><span class="o">.</span><span class="n">Mock</span><span class="p">()</span>
    <span class="n">mock_response</span><span class="o">.</span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Successful&quot;</span>
    <span class="n">mock_response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">=</span> <span class="mi">200</span>

    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">mock_response</span>
    
    <span class="n">actual</span> <span class="o">=</span> <span class="n">get_response</span><span class="p">(</span><span class="s2">&quot;http://example.com/good-request&quot;</span><span class="p">)</span>
    <span class="k">assert</span><span class="p">(</span><span class="n">actual</span> <span class="o">==</span> <span class="s2">&quot;Successful&quot;</span><span class="p">)</span>

<span class="nd">@mock</span><span class="o">.</span><span class="n">patch</span><span class="p">(</span><span class="s2">&quot;requests.get&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_get_response_fail</span><span class="p">(</span><span class="n">mock_requests_get</span><span class="p">):</span>
    <span class="n">mock_response</span> <span class="o">=</span> <span class="n">mock</span><span class="o">.</span><span class="n">Mock</span><span class="p">()</span>
    <span class="n">mock_response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">=</span> <span class="mi">400</span>
    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">mock_response</span>
    
    <span class="k">with</span> <span class="n">pytest</span><span class="o">.</span><span class="n">raises</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">HTTPError</span><span class="p">):</span>
        <span class="n">actual</span> <span class="o">=</span> <span class="n">get_response</span><span class="p">(</span><span class="s2">&quot;http://example.com/bad-request&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>These tests pass successfully. However, if the mocking was implemented incorrectly and the real request executed, our tests may continue to pass depending on how the response was handled by our function. Better practice is to assert that the mock function was called - for example, with <code class="docutils literal notranslate"><span class="pre">mock_function.assert_called()</span></code> or <code class="docutils literal notranslate"><span class="pre">mock_function.assert_called_one_with(parameter)</span></code> - in order be assured of the tests working as expected. Additional stringency comes from matching warnings and error message strings with <code class="docutils literal notranslate"><span class="pre">pytest.raises()</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests/test_handle_api_request.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">src.api_requests</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_response</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">unittest</span><span class="w"> </span><span class="kn">import</span> <span class="n">mock</span>

<span class="nd">@mock</span><span class="o">.</span><span class="n">patch</span><span class="p">(</span><span class="s2">&quot;requests.get&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_get_response_success</span><span class="p">(</span><span class="n">mock_requests_get</span><span class="p">):</span>
    <span class="n">mock_response</span> <span class="o">=</span> <span class="n">mock</span><span class="o">.</span><span class="n">Mock</span><span class="p">()</span>
    <span class="n">mock_response</span><span class="o">.</span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Successful&quot;</span>
    <span class="n">mock_response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">=</span> <span class="mi">200</span>

    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">mock_response</span>
    
    <span class="n">actual</span> <span class="o">=</span> <span class="n">get_response</span><span class="p">(</span><span class="s2">&quot;http://example.com/good-request&quot;</span><span class="p">)</span>
    <span class="k">assert</span><span class="p">(</span><span class="n">actual</span> <span class="o">==</span> <span class="s2">&quot;Successful&quot;</span><span class="p">)</span>

    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">assert_called</span><span class="p">()</span>
    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">assert_called_once_with</span><span class="p">(</span><span class="s2">&quot;http://example.com/good-request&quot;</span><span class="p">)</span>


<span class="nd">@mock</span><span class="o">.</span><span class="n">patch</span><span class="p">(</span><span class="s2">&quot;requests.get&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_get_response_fail</span><span class="p">(</span><span class="n">mock_requests_get</span><span class="p">):</span>
    <span class="n">mock_response</span> <span class="o">=</span> <span class="n">mock</span><span class="o">.</span><span class="n">Mock</span><span class="p">()</span>
    <span class="n">mock_response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">=</span> <span class="mi">400</span>
    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">mock_response</span>
    
    <span class="k">with</span> <span class="n">pytest</span><span class="o">.</span><span class="n">raises</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">HTTPError</span><span class="p">,</span> <span class="n">match</span><span class="o">=</span><span class="s2">&quot;Unsuccessful request&quot;</span><span class="p">):</span>
        <span class="n">get_response</span><span class="p">(</span><span class="s2">&quot;http://example.com/bad-request&quot;</span><span class="p">)</span>

    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">assert_called</span><span class="p">()</span>
    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">assert_called_once_with</span><span class="p">(</span><span class="s2">&quot;http://example.com/bad-request&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Consider using fixtures to make test code more concise by generating the necessary <code class="docutils literal notranslate"><span class="pre">Mock</span></code> object attributes dynamically. Use <a class="reference external" href="https://docs.python.org/3/library/unittest.mock.html#unittest.mock.Mock.reset_mock"><code class="docutils literal notranslate"><span class="pre">Mock.reset_mock()</span></code></a> to remove the attributes associated with a mock object between different test cases.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests/test_handle_api_request.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">src.api_requests</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_response</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">unittest</span><span class="w"> </span><span class="kn">import</span> <span class="n">mock</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;function&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">mock_response</span><span class="p">():</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_create_mock_response</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;factory function allows flexible return values when evaluated&quot;&quot;&quot;</span>
        <span class="n">mock_response</span> <span class="o">=</span> <span class="n">mock</span><span class="o">.</span><span class="n">Mock</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">url</span> <span class="o">==</span> <span class="s2">&quot;http://example.com/good-request&quot;</span><span class="p">:</span>
            <span class="n">mock_response</span><span class="o">.</span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Successful&quot;</span>
            <span class="n">mock_response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">=</span> <span class="mi">200</span>
        <span class="k">elif</span> <span class="n">url</span> <span class="o">==</span> <span class="s2">&quot;http://example.com/bad-request&quot;</span><span class="p">:</span>
            <span class="n">mock_response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">=</span> <span class="mi">400</span>
        <span class="k">return</span> <span class="n">mock_response</span>
    <span class="k">return</span> <span class="n">_create_mock_response</span>


<span class="nd">@mock</span><span class="o">.</span><span class="n">patch</span><span class="p">(</span><span class="s2">&quot;requests.get&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_get_response_all_conditions</span><span class="p">(</span><span class="n">mock_requests_get</span><span class="p">,</span> <span class="n">mock_response</span><span class="p">):</span>

    <span class="n">good_url</span> <span class="o">=</span> <span class="s2">&quot;http://example.com/good-request&quot;</span>
    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">mock_response</span><span class="p">(</span><span class="n">good_url</span><span class="p">)</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="n">get_response</span><span class="p">(</span><span class="n">good_url</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">actual</span> <span class="o">==</span> <span class="s2">&quot;Successful&quot;</span>
    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">assert_called_once_with</span><span class="p">(</span><span class="n">good_url</span><span class="p">)</span>

    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">reset_mock</span><span class="p">()</span>

    <span class="n">bad_url</span> <span class="o">=</span> <span class="s2">&quot;http://example.com/bad-request&quot;</span>
    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">mock_response</span><span class="p">(</span><span class="n">bad_url</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">pytest</span><span class="o">.</span><span class="n">raises</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">HTTPError</span><span class="p">,</span> <span class="n">match</span><span class="o">=</span><span class="s2">&quot;Unsuccessful request&quot;</span><span class="p">):</span>
        <span class="n">get_response</span><span class="p">(</span><span class="n">bad_url</span><span class="p">)</span>
    <span class="n">mock_requests_get</span><span class="o">.</span><span class="n">assert_called_once_with</span><span class="p">(</span><span class="n">bad_url</span><span class="p">)</span>

</pre></div>
</div>
<p><a class="reference external" href="https://docs.pytest.org/en/stable/how-to/monkeypatch.html#how-to-monkeypatch-mock-modules-and-environments">Monkeypatching</a> in <code class="docutils literal notranslate"><span class="pre">pytest</span></code> provides an alternative way of handling mock objects and attributes, and allows for the mocking of environment variables.</p>
</section>
<section id="write-tests-to-assure-that-bugs-are-fixed">
<h2>Write tests to assure that bugs are fixed<a class="headerlink" href="#write-tests-to-assure-that-bugs-are-fixed" title="Link to this heading">#</a></h2>
<p>Each time you find a bug in your code, you should write a new test to assert that the code works correctly.
Once you resolve the issue, this new test should pass and give you confidence that the bug has been fixed.</p>
<p>When you change or refactor your code in future, the new tests
will continue to assure that bugs you have already fixed will not reappear.
Doing this increases the coverage of your tests in a proportionate way.</p>
</section>
<section id="write-tests-before-writing-logic">
<h2>Write tests before writing logic<a class="headerlink" href="#write-tests-before-writing-logic" title="Link to this heading">#</a></h2>
<p>The best practice for testing code is to use test-driven development (TDD).
This is an iterative approach that involves writing tests before writing the logic to meet the tests.</p>
<p>For a piece of analysis logic, you should know in advance what the desired outcome is.
This might be from a user need (for example, someone needs output data in a certain shape) or an internal requirement (for example, you need to impute all missing values).
Given that you know the expected outcome, you can write the test before you think about how you are going to write the solution.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This section is framed more like training. Once dedicated training has been produced this section will likely be adapted to provide more concise guidance on
the practice.</p>
</div>
<p>TDD typically repeats three steps:</p>
<ol class="arabic simple">
<li><p>Red - Write a test that we expect to fail.</p></li>
<li><p>Green - Write or update our code to pass the new test.</p></li>
<li><p>Refactor - Make improvements to the quality of the code without changing the functionality.</p></li>
</ol>
<p>As with any code that is adequately covered by tests, code written using TDD can be safely refactored.
You can be more confident that your tests will capture any changes that would unintentionally alter the way our code works.</p>
<p>Repeat the above three steps to gradually increase the complexity of your code.
The first test you write should focus on the minimum functionality.
Then this minimal functionality is implemented, to do nothing more than the test requires.
On the next iteration the test becomes more complex, as does the code logic.
In each iteration the refactoring steps means that you manage the increasing complexity of the code.</p>
<p>This approach provides many benefits beyond good test coverage.
The iterative nature of TDD encourages you to follow a number of other good practices.
These include keeping test data minimal and keeping functions or classes simple and focussed on doing one thing well.
TDD requires practice but is proven to produce clean, robust and adaptable code.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Behavior-driven_development">Behaviour driven development</a> and
<a class="reference external" href="https://en.wikipedia.org/wiki/Acceptance_test-driven_development">acceptance test driven development</a>
are extensions of TDD with a useful focus on user needs.</p>
</section>
<section id="modelling-relevant-testing">
<h2>Modelling-relevant testing<a class="headerlink" href="#modelling-relevant-testing" title="Link to this heading">#</a></h2>
<p>To ensure you conduct model-relevant tests within the analysis, it is important to use data that is representative of real-world scenarios and free from biases. Select diverse datasets that reflect the variety of conditions the model will encounter in practice. Additionally, it is important to regularly update test data to capture any changes in the environment or user behaviour.</p>
<section id="acceptance-testing">
<h3>Acceptance testing<a class="headerlink" href="#acceptance-testing" title="Link to this heading">#</a></h3>
<p>Acceptance testing ensures that the model meets specified requirements and performs well in real-world scenarios. It verifies that the model’s outputs align with business needs and user expectations. There are three types of acceptance testing:</p>
<p>•	User Acceptance Testing (UAT): End-users test the system to ensure it meets their needs and provides accurate outputs. This involves real-world scenarios where users interact with the model and provide feedback on its performance.</p>
<p>•	Business Acceptance Testing (BAT): Validates that the system meets business requirements and integrates well with existing workflows. This type of testing ensures that the model supports business processes and delivers value to the organization.</p>
<p>•	Operational Acceptance Testing (OAT): Ensures the system is operationally ready, including backup, recovery, and maintenance. This involves testing the model’s performance under different operational conditions to ensure it can handle various scenarios.</p>
</section>
<section id="defining-and-using-appropriate-metrics">
<h3>Defining and Using Appropriate Metrics<a class="headerlink" href="#defining-and-using-appropriate-metrics" title="Link to this heading">#</a></h3>
<p>Evaluating model performance using metrics is essential. Choose metrics that align with the specific goals of the project and provide meaningful insights into the performance of the model in this context.</p>
<p>Use appropriate metrics to evaluate model performance. For example, precision and recall are well established measures for evaluating the performance of data linkage. The right metrics help assess the model’s effectiveness in different scenarios.</p>
</section>
<section id="cross-validation-techniques">
<h3>Cross-Validation Techniques<a class="headerlink" href="#cross-validation-techniques" title="Link to this heading">#</a></h3>
<p>To ensure that the model generalises well to unseen data, you can use techniques like k-fold cross-validation. This method involves dividing the data into k subsets and training the model k times, each time using a different subset as the validation set and the remaining data as the training set. Cross-validation helps identify potential overfitting and ensures that the model performs consistently across different data subsets.</p>
</section>
<section id="stress-testing">
<h3>Stress Testing<a class="headerlink" href="#stress-testing" title="Link to this heading">#</a></h3>
<p>Stress testing evaluates how the model performs under extreme conditions or with noisy data. This helps identify the model’s robustness and ability to handle unexpected inputs. Stress testing involves introducing variations or noise into the input data and observing how this affects the model’s outputs. This type of testing is useful for understanding the model’s limits and ensuring it can handle real-world challenges.</p>
</section>
<section id="sensitivity-analysis">
<h3>Sensitivity Analysis<a class="headerlink" href="#sensitivity-analysis" title="Link to this heading">#</a></h3>
<p>Sensitivity analysis tests how sensitive the model’s outputs are to changes in input data or parameters. This analysis helps understand the model’s behaviour and identify potential weaknesses. Sensitivity analysis involves systematically varying the input data or model parameters and measuring the impact on the model’s outputs. This helps in identifying critical factors that influence the model’s performance and making necessary adjustments.</p>
</section>
<section id="model-interpretability">
<h3>Model Interpretability<a class="headerlink" href="#model-interpretability" title="Link to this heading">#</a></h3>
<p>Implementing methods to make the model’s outputs interpretable is essential for building trust with stakeholders. Techniques like SHAP (SHapley Additive exPlanations) values or LIME (Local Interpretable Model-agnostic Explanations) can help explain the model’s decisions. These methods provide insights into how different features contribute to the model’s outputs, making it easier for analysts and stakeholders to understand and trust the model’s outputs.</p>
</section>
<section id="model-optimisation">
<h3>Model Optimisation<a class="headerlink" href="#model-optimisation" title="Link to this heading">#</a></h3>
<p>Use optimisation to adjust the model’s parameters to achieve the best overall performance. Continuous optimisation ensures that the model remains effective and efficient over time as inputs change. There are lots of techniques available to optimise performance; most are designed to help find the best parameters for the model to enhance its accuracy and efficiency.</p>
<p>Examples of optimisation techniques for machine learning include grid search and parameter tuning. Grid search involves systematically searching through a predefined set of hyperparameters, while hyperparameter tuning adjusts the model’s parameters to achieve the best possible performance.</p>
</section>
</section>
<section id="reduce-repetition-in-test-code-fixtures-and-parameterised-tests">
<h2>Reduce repetition in test code (fixtures and parameterised tests)<a class="headerlink" href="#reduce-repetition-in-test-code-fixtures-and-parameterised-tests" title="Link to this heading">#</a></h2>
<p>Where possible, you should reduce repetition in your tests. Tests are code too, so you should still <a class="reference internal" href="modular_code.html#functions"><span class="std std-ref">make this code reusable</span></a>.
As with functional code, test code is much easier to maintain when it is modular and reusable.</p>
<section id="use-fixtures-to-reduce-repetition-in-test-set-up">
<h3>Use fixtures to reduce repetition in test set up<a class="headerlink" href="#use-fixtures-to-reduce-repetition-in-test-set-up" title="Link to this heading">#</a></h3>
<p>As your test suite grows, many of your tests may use similar code to prepare your tests or to clean up after each test has run.
You can be more tolerant of repetition in test code.
However, copying code snippets for each test is laborious and increases the risk of applying those steps inconsistently.</p>
<p>You can use fixtures to help avoid this form of repetition in tests.
A fixture allows you to define your test preparation and clean up as functions.
You then use the fixture to carry out these steps consistently for each test that they are required for.</p>
<p>In Class-based testing frameworks, these functions tend to be separated into <code class="docutils literal notranslate"><span class="pre">SetUp</span></code> and <code class="docutils literal notranslate"><span class="pre">TearDown</span></code> functions.
These are set to run before and after each test, respectively.</p>
<p>Fixtures can be most useful when setting up a test object takes a large amount of time or resource.
They can be designed to run for each test, once for a group of tests or once for the whole test suite.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql</span><span class="w"> </span><span class="kn">import</span> <span class="n">SparkSession</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;session&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">spark_session</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Session-wide SparkSession to optimise testing PySpark functions.&quot;&quot;&quot;</span>
    <span class="n">spark_session</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[*]&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
    <span class="k">yield</span> <span class="n">spark_session</span>
    <span class="n">spark_session</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_my_function</span><span class="p">(</span><span class="n">spark_session</span><span class="p">):</span>
    <span class="o">...</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_another_function</span><span class="p">(</span><span class="n">spark_session</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>This example shows a fixture named <code class="docutils literal notranslate"><span class="pre">spark_session</span></code> with a testing session scope.
Starting a new spark session can take a few seconds, so creating a new session
for each test function would significantly increase the time it takes to run all of the tests.
With a session level scope, you call the function once for the whole testing session
and share the resulting <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> object between your tests.
Reusing the same <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> object is safe to do if none of our tests modify the object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;function&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">database_connection</span><span class="p">():</span>
    <span class="n">database_connection</span> <span class="o">=</span> <span class="n">connect_to_test_database</span><span class="p">()</span>
    <span class="k">yield</span> <span class="n">database_connection</span>
    <span class="n">database_connection</span><span class="o">.</span><span class="n">reset_to_default</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_my_function</span><span class="p">(</span><span class="n">database_connection</span><span class="p">):</span>
    <span class="o">...</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_another_function</span><span class="p">(</span><span class="n">database_connection</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>Fixtures can also be useful for undoing any effects that each test run might have on the global environment.
For example, they can remove test data which has been written to a temporary file or database.
The example above shows how you might use a fixture to reset a test database between each test.
It uses a test function scope, so the fixture is run separately for each test function that uses it.
The fixture performs a reset on the database after the database connection has been used by the test.</p>
<p>For usage details see the documentation for packages that offer fixtures:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.pytest.org/en/stable/fixture.html">Python <code class="docutils literal notranslate"><span class="pre">pytest</span></code> Fixture</a> documentation</p></li>
<li><p><a class="reference external" href="https://testthat.r-lib.org/articles/test-fixtures.html">R <code class="docutils literal notranslate"><span class="pre">testthat</span></code> Fixture</a> documentation</p></li>
</ul>
</section>
<section id="use-parameterisation-to-reduce-repetition-in-test-logic">
<h3>Use parameterisation to reduce repetition in test logic<a class="headerlink" href="#use-parameterisation-to-reduce-repetition-in-test-logic" title="Link to this heading">#</a></h3>
<p>Similar steps are often repeated when testing multiple combinations of inputs and outputs.
Parameterisation allows reduction of repetition in test code, in a similar way to writing your logic in functions.
Specify pairs of inputs and expected outputs, so your testing tool can repeat the same test for each scenario.</p>
<p>Using parameterisation in a test framework is equivalent to using a for-loop to apply a test function over multiple inputs and expected outputs.
Using functionality from test packages may provide improved running efficiency and more detailed reporting of test failures.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">pytest</span></code>, this can be achieved using the <a class="reference external" href="https://docs.pytest.org/en/stable/parametrize.html">Parametrize mark</a>.</p>
<p>In R, the <code class="docutils literal notranslate"><span class="pre">patrick</span></code> package extends <code class="docutils literal notranslate"><span class="pre">testthat</span></code> to provide a
<a class="reference external" href="https://rdrr.io/cran/patrick/man/with_parameters_test_that.html"><code class="docutils literal notranslate"><span class="pre">with_parameters_test_that</span></code></a> function to achieve this.</p>
</section>
<section id="define-source-code">
<h3>Define Source Code<a class="headerlink" href="#define-source-code" title="Link to this heading">#</a></h3>
<p>Take the below function for example, which can take 2 arguments.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sum_two_nums</span><span class="p">(</span><span class="n">num1</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">num2</span><span class="p">:</span><span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sum two numbers. Numbers can be integer or float.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">num1</span> <span class="o">+</span> <span class="n">num2</span>
</pre></div>
</div>
</section>
<section id="simple-parameterisation">
<h3>Simple Parameterisation<a class="headerlink" href="#simple-parameterisation" title="Link to this heading">#</a></h3>
<p>It is simple to check multiple assertions for this simple function. In the most
basic example, simply define a parameterised list of parameter values and
expected outcomes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">&quot;num_1s, expected_out&quot;</span><span class="p">,</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_sum_two_nums_parameterise_arg_1</span><span class="p">(</span><span class="n">num_1s</span><span class="p">,</span> <span class="n">expected_out</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">sum_two_nums</span><span class="p">(</span><span class="n">num1</span><span class="o">=</span><span class="n">num_1s</span><span class="p">,</span> <span class="n">num2</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">expected_out</span>
</pre></div>
</div>
<p>We reference the parameter values and expected answers in the same way that we
access pytest fixtures, covered earlier in this article. Running <code class="docutils literal notranslate"><span class="pre">pytest</span> <span class="pre">-v</span></code>
reveals 3 tests are run, with the parameterised values printed to the console:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">collected</span> <span class="mi">3</span> <span class="n">items</span>                                                             

<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_parameterise_arg_1</span><span class="p">[</span><span class="mi">1</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="n">PASSED</span>                  <span class="p">[</span> <span class="mi">33</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_parameterise_arg_1</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="mi">0</span><span class="p">]</span> <span class="n">PASSED</span>                 <span class="p">[</span> <span class="mi">66</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_parameterise_arg_1</span><span class="p">[</span><span class="mi">0</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="n">PASSED</span>                  <span class="p">[</span><span class="mi">100</span><span class="o">%</span><span class="p">]</span>

<span class="o">=============================</span> <span class="mi">3</span> <span class="n">passed</span> <span class="ow">in</span> <span class="mf">0.00</span><span class="n">s</span> <span class="o">==============================</span>
</pre></div>
</div>
<p>It would be trivial to repeat a similar parameterised test for <code class="docutils literal notranslate"><span class="pre">num_2</span></code> values.
But how is it possible to make assertions when parameterising <strong>both</strong>
arguments?</p>
</section>
<section id="stacked-parameterisation">
<h3>Stacked Parameterisation<a class="headerlink" href="#stacked-parameterisation" title="Link to this heading">#</a></h3>
<p>In order to test multiple values for <code class="docutils literal notranslate"><span class="pre">num1</span></code> and <code class="docutils literal notranslate"><span class="pre">num2</span></code>, a fixture should be
defined that returns a dictionary of the expected values. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span><span class="w"> </span><span class="nf">expected_answers</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A nested dictionary of expected answers for all combinations in 0:5.</span>

<span class="sd">    First level key corresponds to `num1` and the second level key to `num2`.</span>
<span class="sd">    The dictionary values are the expected answers. So that when we subset the</span>
<span class="sd">    dictionary with parameterised values, we provide the expected values to</span>
<span class="sd">    assert statements.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        Dictionary of cases and their expected tuples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">expected</span><span class="o">=</span> <span class="p">{</span>
        <span class="mi">0</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">4</span><span class="p">,},</span>
        <span class="mi">1</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">5</span><span class="p">,},</span>
        <span class="mi">2</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">6</span><span class="p">,},</span>
        <span class="mi">3</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">7</span><span class="p">,},</span>
        <span class="mi">4</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">8</span><span class="p">,},</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">expected</span>
</pre></div>
</div>
<p>This fixture of expected answers can be served to a parameterised test and the
returned dictionary can be accessed to provide the expected answer for
parameter combinations. To parameterise both of the required arguments,
the parameterise statements are simply stacked on top of each other:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">&quot;num1s&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">&quot;num2s&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_sum_two_nums_stacked_parameterise</span><span class="p">(</span><span class="n">num1s</span><span class="p">,</span> <span class="n">num2s</span><span class="p">,</span> <span class="n">expected_answers</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">sum_two_nums</span><span class="p">(</span>
        <span class="n">num1</span><span class="o">=</span><span class="n">num1s</span><span class="p">,</span> <span class="n">num2</span><span class="o">=</span><span class="n">num2s</span>
        <span class="p">)</span> <span class="o">==</span> <span class="n">expected_answers</span><span class="p">[</span><span class="n">num1s</span><span class="p">][</span><span class="n">num2s</span><span class="p">]</span>
</pre></div>
</div>
<p>Executing this test with <code class="docutils literal notranslate"><span class="pre">pytest</span> <span class="pre">-v</span></code> shows all combinations are tested:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">collected</span> <span class="mi">25</span> <span class="n">items</span>                                                            

<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">0</span><span class="o">-</span><span class="mi">0</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">14</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">0</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">17</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">0</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">21</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">0</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">25</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">0</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">28</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">1</span><span class="o">-</span><span class="mi">0</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">32</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">35</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">1</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">39</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">1</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">42</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">1</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">46</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">2</span><span class="o">-</span><span class="mi">0</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">50</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">53</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">2</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">57</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">2</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">60</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">2</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">64</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">3</span><span class="o">-</span><span class="mi">0</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">67</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">3</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">71</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">3</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">75</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">3</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">78</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">3</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">82</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">4</span><span class="o">-</span><span class="mi">0</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">85</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">4</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">89</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">4</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">92</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">4</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span> <span class="mi">96</span><span class="o">%</span><span class="p">]</span>
<span class="n">foo</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_sum_two_nums_stacked_parameterise</span><span class="p">[</span><span class="mi">4</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span> <span class="n">PASSED</span>                <span class="p">[</span><span class="mi">100</span><span class="o">%</span><span class="p">]</span>

<span class="o">=============================</span> <span class="mi">25</span> <span class="n">passed</span> <span class="ow">in</span> <span class="mf">0.01</span><span class="n">s</span> <span class="o">=============================</span>
</pre></div>
</div>
</section>
</section>
<section id="testing-sql">
<h2>Testing SQL<a class="headerlink" href="#testing-sql" title="Link to this heading">#</a></h2>
<p>Although testing SQL is outside the scope of this guidance, many of the concepts discussed
in this guidance are also applicable to SQL. In SQL,
single queries often contain several parts. These can be more readily
tested by breaking up these queries and taking a more step-by-step approach,
similar to breaking up functions. Use <a class="reference internal" href="#test-that-different-parts-of-the-code-interact-correctly-using-integration-tests">Integration testing</a> to verify
that queries and functions behave as expected when combined.</p>
<p>Test functions that interact with a database (DB) within a development
environment, rather than with a production database. This prevents
unintended data modification or deletion. Functions can also be unit tested
from simplified dummy data.</p>
<p>There are a range of established SQL testing frameworks. Examples include <a class="reference external" href="https://github.com/tSQLt-org/tSQLt">tSQLt</a>
and <a class="reference external" href="https://github.com/theory/pgtap/">pgTAP</a> for Postgres.</p>
</section>
<section id="in-a-time-crunch-the-risks-to-skipping-tests">
<h2>In a time crunch? The risks to skipping tests<a class="headerlink" href="#in-a-time-crunch-the-risks-to-skipping-tests" title="Link to this heading">#</a></h2>
<p>In an ideal world, you would never skip testing code, ensuring the software is reliable
and easily reproducible. However, in practice there are times when skipping tests may be necessary —
perhaps due to tight deadlines, limited resources, or the need to quickly get a feature up
and running. While this can save time in the moment, it’s important to be cautious, as
skipping tests can lead to hidden problems that may become harder to fix later, particularly
as the project grows. Whenever tests are set aside, it’s best to have a plan for going back to add
them, to avoid risks to the stability and quality of the software.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="peer_review.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Peer review</p>
      </div>
    </a>
    <a class="right-next"
       href="continuous_integration.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Automating code quality assurance</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-should-i-test">What should I test?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-are-tests-structured">How are tests structured?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#write-reproducible-tests">Write reproducible tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#write-repeatable-tests">Write repeatable tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-all-tests-against-each-change-to-your-code">Run all tests against each change to your code</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#record-the-outcomes-of-your-tests">Record the outcomes of your tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minimise-your-test-data">Minimise your test data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#structure-test-files-to-match-code-structure">Structure test files to match code structure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#structuring-tests">Structuring tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-that-new-logic-is-correct-using-unit-tests">Test that new logic is correct using unit tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-that-different-parts-of-the-code-interact-correctly-using-integration-tests">Test that different parts of the code interact correctly using integration tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-that-the-analysis-runs-as-expected-using-end-to-end-tests">Test that the analysis runs as expected using end-to-end tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#good-practices-for-integration-and-end-to-end-testing">Good practices for integration and end-to-end testing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#isolate-code-tests-from-external-systems">Isolate code tests from external systems</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#write-tests-to-assure-that-bugs-are-fixed">Write tests to assure that bugs are fixed</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#write-tests-before-writing-logic">Write tests before writing logic</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelling-relevant-testing">Modelling-relevant testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#acceptance-testing">Acceptance testing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-and-using-appropriate-metrics">Defining and Using Appropriate Metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation-techniques">Cross-Validation Techniques</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stress-testing">Stress Testing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sensitivity-analysis">Sensitivity Analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-interpretability">Model Interpretability</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-optimisation">Model Optimisation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reduce-repetition-in-test-code-fixtures-and-parameterised-tests">Reduce repetition in test code (fixtures and parameterised tests)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-fixtures-to-reduce-repetition-in-test-set-up">Use fixtures to reduce repetition in test set up</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-parameterisation-to-reduce-repetition-in-test-logic">Use parameterisation to reduce repetition in test logic</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-source-code">Define Source Code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-parameterisation">Simple Parameterisation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stacked-parameterisation">Stacked Parameterisation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-sql">Testing SQL</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#in-a-time-crunch-the-risks-to-skipping-tests">In a time crunch? The risks to skipping tests</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>Analysis Function - Analytical Standards and Pipelines hub</p><p>This is a living document, please help use to make it grow by providing any feedback <a href='mailto:ASAP@ons.gov.uk'>by email</a> or via the <a href='https://github.com/best-practice-and-impact/qa-of-code-guidance'>GitHub repository</a>.
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>